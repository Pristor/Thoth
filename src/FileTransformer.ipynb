{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from data_source import preproc as pp\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import string\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    \"\"\"\n",
    "        Dataset class functions:\n",
    "            read_iam: reads the lines from iam Dataset saves test, valid and train set in a dict\n",
    "            dataset structure : {train:{dt:[], gt:[]}, valid:{dt:[], gt:[]}, test:{dt:[], gt:[]}}\n",
    "            \n",
    "            preprocess_partitions preprocesses the data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, iam_path):\n",
    "        \n",
    "        self.iam_path = iam_path\n",
    "        self.dataset = None\n",
    "        self.partitions = ['train', 'valid', 'test']\n",
    "        \n",
    "    \n",
    "    def read_iam(self):\n",
    "        \"\"\"reads iam dataset\"\"\"\n",
    "        pt_path = os.path.join(self.iam_path, \"partitions\")\n",
    "        paths = {\"train\": open(os.path.join(pt_path, \"trainset.txt\")).read().splitlines(),\n",
    "                 \"valid\": open(os.path.join(pt_path, \"validationset1.txt\")).read().splitlines(),\n",
    "                 \"test\": open(os.path.join(pt_path, \"testset.txt\")).read().splitlines()}\n",
    "        \n",
    "        lines = open(os.path.join(self.iam_path, \"lines.txt\")).read().splitlines()\n",
    "        gt_dict = dict()\n",
    "        \n",
    "        for line in lines:\n",
    "            if (not line or line[0]== \"#\"):\n",
    "                continue\n",
    "            \n",
    "            splitted = line.split()\n",
    "            \n",
    "            if splitted[1] == \"ok\":\n",
    "                gt_dict[splitted[0]] = \" \".join(splitted[8::]).replace(\"|\",\" \")\n",
    "            \n",
    "        dataset = dict()\n",
    "        \n",
    "        for i in self.partitions:\n",
    "            dataset[i] = {\"dt\": [], \"gt\": []}\n",
    "            \n",
    "            for line in paths[i]:\n",
    "                try:\n",
    "                    split = line.split(\"-\")\n",
    "                    \n",
    "                    folder = f\"{split[0]}-{split[1]}\"\n",
    "                    image = f\"{split[0]}-{split[1]}-{split[2]}.png\"\n",
    "                    \n",
    "                    image_path = os.path.join(self.iam_path, \"lines\", split[0], folder, image)\n",
    "                    \n",
    "                    dataset[i]['gt'].append(gt_dict[line])\n",
    "                    dataset[i]['dt'].append(image_path)\n",
    "                    \n",
    "                except KeyError:\n",
    "                    pass\n",
    "                \n",
    "        self.dataset = dataset\n",
    "                \n",
    "    \n",
    "    def preprocess_partitions(self, input_size):\n",
    "        \"\"\" function to preprocess the data, removes bad samples, preprocesses images\"\"\"\n",
    "        \n",
    "        print(\"Partitions will be preprocessed...\")\n",
    "        \n",
    "        for i in self.partitions:\n",
    "            \n",
    "            arange = range(len(self.dataset[i]['gt']))\n",
    "            \n",
    "            for j in reversed(arange):\n",
    "                #handles spaces around punctations\n",
    "                text = pp.text_standardize(self.dataset[i]['gt'][j])\n",
    "                \n",
    "                if not self.check_text(text):\n",
    "                    #remove if the example has more punctations than letters\n",
    "                    self.dataset[i]['gt'].pop(j)\n",
    "                    self.dataset[i]['dt'].pop(j)\n",
    "                    continue\n",
    "                \n",
    "                self.dataset[i]['gt'][j] = text.encode()\n",
    "                \n",
    "            pool = Pool()\n",
    "            #multiprocess: apllies pp.preprocess on each value of the array\n",
    "            #partial -> changes args of function\n",
    "            self.dataset[i]['dt'] = pool.map(partial(pp.preprocess, input_size=input_size), self.dataset[i]['dt'])\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "            \n",
    "        print(\"Partitions preprocessing finished\")\n",
    "    \n",
    "    def save(self, source_path):\n",
    "        \"saves partitions as hdf5\"\n",
    "        os.makedirs(os.path.dirname(source_path), exist_ok=True)\n",
    "        \n",
    "        for i in self.partitions:\n",
    "            with h5py.File(source_path, \"a\") as hf:\n",
    "                hf.create_dataset(f\"{i}/dt\", data=ds.dataset[i]['dt'], compression=\"gzip\", compression_opts=9)\n",
    "                hf.create_dataset(f\"{i}/gt\", data=ds.dataset[i]['gt'], compression=\"gzip\", compression_opts=9)\n",
    "                print(f\"[OK] {i} partition.\")\n",
    "\n",
    "        print(f\"Transformation finished.\")\n",
    "            \n",
    "                \n",
    "                \n",
    "    \n",
    "    @staticmethod\n",
    "    def check_text(text):\n",
    "        \"\"\"Make sure text has more characters instead of punctuation marks\"\"\"\n",
    "\n",
    "        strip_punc = text.strip(string.punctuation).strip()\n",
    "        no_punc = text.translate(str.maketrans(\"\", \"\", string.punctuation)).strip()\n",
    "\n",
    "        if len(text) == 0 or len(strip_punc) == 0 or len(no_punc) == 0:\n",
    "            return False\n",
    "\n",
    "        punc_percent = (len(strip_punc) - len(no_punc)) / len(strip_punc)\n",
    "\n",
    "        return len(no_punc) >= 2 and punc_percent <= 0.1\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
